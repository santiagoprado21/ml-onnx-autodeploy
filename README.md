# Sistema de Despliegue Autom√°tico para Modelos ONNX

Sistema completo de CI/CD para despliegue autom√°tico de modelos de Machine Learning en formato ONNX, con endpoints separados para desarrollo y producci√≥n.

## üéØ Prop√≥sito del Proyecto

Este repositorio implementa un **sistema de despliegue autom√°tico (MLOps)** que permite actualizar modelos de Machine Learning en producci√≥n de forma segura, r√°pida y sin intervenci√≥n manual.

### Problema que resuelve

En producci√≥n, actualizar modelos ML manualmente es:
- ‚è±Ô∏è **Lento**: Puede tomar horas de trabajo manual
- üêõ **Propenso a errores**: Riesgo de romper el servicio
- üí∞ **Costoso**: Requiere personal DevOps dedicado
- üîÑ **No escalable**: Dif√≠cil de mantener con m√∫ltiples modelos

### Soluci√≥n propuesta

Un pipeline automatizado que:
- ‚úÖ **Prueba** el modelo antes de desplegarlo
- ‚úÖ **Despliega** autom√°ticamente si pasa las pruebas
- ‚úÖ **Separa** entornos de desarrollo y producci√≥n
- ‚úÖ **Registra** todas las predicciones para monitoreo
- ‚úÖ **Funciona 24/7** sin intervenci√≥n humana

### Caso de uso

**Modelo implementado:** Clasificador de d√≠gitos manuscritos (MNIST)
- **Entrada:** Imagen de 28x28 p√≠xeles (784 valores)
- **Salida:** D√≠gito reconocido (0-9)
- **Aplicaci√≥n real:** Reconocimiento de n√∫meros en cheques, formularios, documentos escaneados

## üèóÔ∏è Arquitectura del Sistema

### Componentes principales

```

![Diagrama de arquitectura](assets/MLFinalProject.png)

```

### Tecnolog√≠as utilizadas

- **Modelo ONNX**: Almacenado en S3, descargado din√°micamente (nunca en el repo)
- **Datos de prueba**: En S3, descargados en pipeline CI/CD
- **Logs de predicci√≥n**: Guardados autom√°ticamente en S3 (`predicciones_dev.txt`, `predicciones_prod.txt`)
- **API**: FastAPI sirviendo predicciones del modelo
- **Contenedores**: Docker + AWS ECR
- **Orquestaci√≥n**: AWS ECS Fargate
- **CI/CD**: GitHub Actions

## üìÅ Estructura del Repositorio

```
/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ test-and-deploy.yml    # Pipeline CI/CD
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # API FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile             # Imagen del contenedor
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ download_model.py      # Descarga modelo desde S3
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py       # Descarga datos de prueba
‚îÇ   ‚îî‚îÄ‚îÄ upload_prediction_log.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py          # Tests unitarios
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Pipeline CI/CD

### Ramas y Endpoints

| Rama | Servicio ECS | Endpoint | Archivo de logs |
|------|-------------|----------|-----------------|
| `dev` | api-dev | http://44.210.82.145 | predicciones_dev.txt |
| `prod` | api-prod | http://34.204.77.202 | predicciones_prod.txt |

### Etapas del Pipeline

**1. Test**
- Descarga modelo ONNX desde S3
- Descarga datos de prueba desde S3
- Ejecuta pruebas unitarias:
  - Verifica que el modelo responde correctamente
  - Valida m√©tricas de rendimiento

**2. Build & Deploy**
- Construye imagen Docker
- Sube imagen a AWS ECR
- Actualiza servicio ECS correspondiente (dev o prod)

## ‚öôÔ∏è Configuraci√≥n Inicial

### 1. Recursos AWS

**S3 Bucket** (`projectofinalml-santiagoprado`):
```
modelo.onnx
test_data.csv
test_labels.csv
predicciones_dev.txt (vac√≠o inicial)
predicciones_prod.txt (vac√≠o inicial)
```

**ECR Repositories**:
- `ml-onnx-autodeploy-dev`
- `ml-onnx-autodeploy-prod`

**ECS Cluster**: `ml-autodeploy-cluster`

**ECS Services**:
- `api-dev` (con variable `APP_ENV=dev`)
- `api-prod` (con variable `APP_ENV=prod`)

### 2. Secrets de GitHub

En Settings > Secrets > Actions, agregar:
```
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
AWS_ACCOUNT_ID
AWS_DEFAULT_REGION (ej: us-east-1)
```

### 3. Variables de Entorno

```bash
MODEL_URL=https://projectofinalml-santiagoprado.s3.amazonaws.com/mnist-8.onnx
TEST_DATA_URL=https://projectofinalml-santiagoprado.s3.amazonaws.com/test_data.csv
TEST_LABELS_URL=https://projectofinalml-santiagoprado.s3.amazonaws.com/test_labels.csv
APP_ENV=dev  # o prod
AWS_ACCESS_KEY_ID=tu-key
AWS_SECRET_ACCESS_KEY=tu-secret
AWS_DEFAULT_REGION=us-east-1
```

## üß™ Uso Local

### Instalar dependencias
```bash
pip install -r app/requirements.txt pytest
```

### Descargar modelo y datos
```bash
export MODEL_URL=https://projectofinalml-santiagoprado.s3.amazonaws.com/mnist-8.onnx
python scripts/download_model.py
python scripts/download_data.py
```

### Ejecutar tests
```bash
pytest tests/
```

### Correr API localmente
```bash
export APP_ENV=dev
uvicorn app.main:app --reload
```

### Hacer predicci√≥n
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"data": [0.1, 0.2, ..., 0.5]}'  # 784 valores para MNIST
```

**Respuesta esperada:**
```json
{
  "prediction": 7
}
```

### Probar endpoints en vivo
```bash
python test_endpoints.py
```

**Output:**
```
==================================================
PROBANDO ENDPOINTS ML
==================================================

üîµ Probando endpoint DEV...
Status: 200
Respuesta: {'prediction': 7}

üü¢ Probando endpoint PROD...
Status: 200
Respuesta: {'prediction': 3}

==================================================
‚úÖ Pruebas completadas
==================================================
```

## üîÑ Flujo de Trabajo Completo

### Ciclo de vida del despliegue

```
1. Desarrollador hace cambios en c√≥digo
   ‚Üì
2. git push origin dev
   ‚Üì
3. GitHub Actions detecta el push
   ‚Üì
4. ETAPA TEST:
   - Descarga modelo desde S3
   - Descarga datos de prueba desde S3
   - Ejecuta tests unitarios
   - ¬øPasan? ‚Üí Contin√∫a | ¬øFallan? ‚Üí Detiene pipeline
   ‚Üì
5. ETAPA BUILD:
   - Construye imagen Docker
   - Etiqueta con SHA del commit
   - Sube imagen a AWS ECR
   ‚Üì
6. ETAPA DEPLOY:
   - Actualiza servicio ECS (api-dev)
   - ECS descarga nueva imagen
   - Reemplaza contenedor antiguo
   - Endpoint actualizado (sin downtime)
   ‚Üì
7. Usuario hace request a /predict
   ‚Üì
8. API procesa y devuelve predicci√≥n
   ‚Üì
9. Predicci√≥n se guarda en S3 (predicciones_dev.txt)
```

### Promoci√≥n a producci√≥n

1. **Desarrollo**: Hacer cambios en rama `dev`
2. **Push**: `git push origin dev`
3. **CI/CD autom√°tico**: Tests + Build + Deploy a dev
4. **Validaci√≥n**: Probar endpoint dev
5. **Promoci√≥n a prod**: Merge `dev` ‚Üí `prod`
6. **Deploy prod**: Pipeline actualiza `api-prod`

## üìä Monitoreo

Cada predicci√≥n se registra autom√°ticamente en S3:
- `predicciones_dev.txt`: logs del endpoint dev
- `predicciones_prod.txt`: logs del endpoint prod

Formato: una predicci√≥n por l√≠nea.

## üõ†Ô∏è Troubleshooting

**Error: Unable to assume service linked role**
```bash
aws iam create-service-linked-role --aws-service-name ecs.amazonaws.com
```

**Error: No images found in ECR**
- Hacer push inicial manual o esperar primer pipeline exitoso

**Error: boto3 credentials**
- Verificar variables de entorno AWS_ACCESS_KEY_ID y AWS_SECRET_ACCESS_KEY

## üìù Requisitos Cumplidos

‚úÖ Repositorio GitHub con CI/CD  
‚úÖ Dos ramas (dev y prod) con endpoints separados  
‚úÖ Etapa test: descarga modelo/datos, ejecuta pruebas  
‚úÖ Etapa build/promote: construye y despliega contenedor  
‚úÖ Modelo ONNX NO en repo, solo referencia  
‚úÖ Datos de prueba descargados din√°micamente  
‚úÖ Logs de predicci√≥n en archivos TXT en S3  
‚úÖ Pipeline ejecuta en cada push a dev/prod  

## üìö Tecnolog√≠as

- Python 3.10
- FastAPI
- ONNX Runtime
- Docker
- AWS (S3, ECR, ECS, Fargate)
- GitHub Actions
- boto3

## üë§ Autor

Santiago Prado - Proyecto Final ML
